{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fb96c7",
   "metadata": {},
   "source": [
    "# COMP 352 - Final Project: Footballer Market Evaluation\n",
    "\n",
    "**Author:** Zevin Attisha, Santi Guerrero, Santiago Pedetti, Christian Vaikona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a986aa",
   "metadata": {},
   "source": [
    "#### Full dataset: https://www.kaggle.com/datasets/davidcariboo/player-scores/data?select=appearances.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fcb23",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Environment Setup](#env-setup)\n",
    "* [Data Importing and Pre-processing](#data-importing)\n",
    "* [Data Analysis and Visualization](#data-vis)\n",
    "* [Data Analytics](#data-analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac7f6f",
   "metadata": {},
   "source": [
    "## Environment Setup <a class=\"anchor\" id=\"env-setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1dbaf5",
   "metadata": {},
   "source": [
    "(COPIED AND PASTED - EDIT LATER)\n",
    "\n",
    "First we must setup our environment to make sure we have all appropriate modules installed. To do this, I have provided 2 methods. The 1st, is to install all modules using a ```.yaml``` file via ```conda```. \n",
    "\n",
    "To do this, run:\n",
    "```bash\n",
    "conda env create -f env_setup/data_environment.yml\n",
    "```\n",
    "Then activate the environment by:\n",
    "```bash\n",
    "conda activate data_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e091322",
   "metadata": {},
   "source": [
    "(COPIED AND PASTED - EDIT LATER)\n",
    "\n",
    "You can also use the ```requirements.txt``` file to download the modules via ```pip```.\n",
    "\n",
    "To do this, first make create and activate your environment:\n",
    "```bash\n",
    "conda create -n my_data_env\n",
    "conda activate my_data_env\n",
    "```\n",
    "\n",
    "You may need to install setup tools. To do this run (Note you may need to change ```pip3``` to ```pip```):\n",
    "```bash\n",
    "pip3 install --upgrade pip setuptools wheel\n",
    "```\n",
    "\n",
    "and then run:\n",
    "```bash\n",
    "pip3 install -r env_setup/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7c2e2",
   "metadata": {},
   "source": [
    "## Data Importing and Pre-processing <a class=\"anchor\" id=\"data-importing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6d947",
   "metadata": {},
   "source": [
    "Section Overview:\n",
    "\n",
    "- Import dataset and describe characteristics such as dimensions, data types, file types, and import methods used\n",
    "- Clean, wrangle, and handle missing data, duplicate data, etc.\n",
    "- Encode any categorical variables\n",
    "- Perform feature engineering on the dataset\n",
    "- Transform data appropriately using techniques such as aggregation, normalization, and feature construction\n",
    "- Reduce redundant data and perform need based discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ac1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import warnings\n",
    "\n",
    "import branca\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from branca.element import Figure\n",
    "from folium import Marker\n",
    "from folium.plugins import HeatMap\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import norm, probplot, skew\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from utils.model_scripts import (\n",
    "    hello\n",
    ")\n",
    "from utils.metric_scripts import (\n",
    "    hello\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas.*\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595e2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files\n",
    "player_valuations_df = pd.read_csv(\"data/raw/player_valuations.csv\")\n",
    "players_df = pd.read_csv(\"data/raw/players.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b8c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_valuations.csv dimensions: (496606, 5)\n",
      "players.csv dimensions: (32601, 23)\n"
     ]
    }
   ],
   "source": [
    "# dimensions of each df\n",
    "print(\"player_valuations.csv dimensions: \" + str(player_valuations_df.shape))\n",
    "print(\"players.csv dimensions: \" + str(players_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f860773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For player_valuations.csv Data:\n",
      "# of categorical values: 2\n",
      "# of continuous variables: 2\n",
      "For players.csv Data:\n",
      "# of categorical values: 17\n",
      "# of continuous variables: 5\n"
     ]
    }
   ],
   "source": [
    "# count the number of categorical variables\n",
    "\n",
    "pv_cat_count = 0\n",
    "for dtype in player_valuations_df.dtypes:\n",
    "    if dtype == \"object\":\n",
    "        pv_cat_count +=1\n",
    "\n",
    "pv_numeric_vars = player_valuations_df.shape[1] - pv_cat_count - 1 # subtract an extra column as 1 column is an ID column\n",
    "\n",
    "print(\"For player_valuations.csv Data:\")\n",
    "print(\"# of categorical values: \" + str(pv_cat_count))\n",
    "print(\"# of continuous variables:\", str(pv_numeric_vars)+\"\\n\")\n",
    "\n",
    "p_cat_count = 0\n",
    "for dtype in players_df.dtypes:\n",
    "    if dtype == \"object\":\n",
    "        p_cat_count +=1\n",
    "\n",
    "p_numeric_vars = players_df.shape[1] - p_cat_count - 1 # subtract an extra column as 1 column is an ID column\n",
    "\n",
    "print(\"For players.csv Data:\")\n",
    "print(\"# of categorical values: \" + str(p_cat_count))\n",
    "print(\"# of continuous variables:\", str(p_numeric_vars)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf8fc1",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization <a class=\"anchor\" id=\"data-vis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932640b",
   "metadata": {},
   "source": [
    "Section Overview:\n",
    "\n",
    "- Identify categorical, ordinal, and numerical variables within data\n",
    "- Provide measures of centrality and distribution with visualizations\n",
    "- Diagnose for correlations between variables and determine independent and dependent variables\n",
    "- Perform exploratory analysis in combination with visualization techniques to discover patterns and features of interest\n",
    "- Create visualizations that allow for the discovery of insights in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889b2d8",
   "metadata": {},
   "source": [
    "## Data Analytics <a class=\"anchor\" id=\"data-analytics\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
