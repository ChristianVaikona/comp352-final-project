{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fb96c7",
   "metadata": {},
   "source": [
    "# COMP 352 - Final Project: Footballer Market Evaluation\n",
    "\n",
    "**Author:** Zevin Attisha, Santi Guerrero, Santiago Pedetti, Christian Vaikona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a986aa",
   "metadata": {},
   "source": [
    "#### Full dataset: https://www.kaggle.com/datasets/davidcariboo/player-scores/data?select=appearances.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fcb23",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Environment Setup](#env-setup)\n",
    "* [Data Importing and Pre-processing](#data-importing)\n",
    "* [Data Analysis and Visualization](#data-vis)\n",
    "* [Data Analytics](#data-analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac7f6f",
   "metadata": {},
   "source": [
    "## Environment Setup <a class=\"anchor\" id=\"env-setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1dbaf5",
   "metadata": {},
   "source": [
    "(COPIED AND PASTED - EDIT LATER)\n",
    "\n",
    "First we must setup our environment to make sure we have all appropriate modules installed. To do this, I have provided 2 methods. The 1st, is to install all modules using a ```.yaml``` file via ```conda```. \n",
    "\n",
    "To do this, run:\n",
    "```bash\n",
    "conda env create -f env_setup/data_environment.yml\n",
    "```\n",
    "Then activate the environment by:\n",
    "```bash\n",
    "conda activate data_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e091322",
   "metadata": {},
   "source": [
    "(COPIED AND PASTED - EDIT LATER)\n",
    "\n",
    "You can also use the ```requirements.txt``` file to download the modules via ```pip```.\n",
    "\n",
    "To do this, first make create and activate your environment:\n",
    "```bash\n",
    "conda create -n my_data_env\n",
    "conda activate my_data_env\n",
    "```\n",
    "\n",
    "You may need to install setup tools. To do this run (Note you may need to change ```pip3``` to ```pip```):\n",
    "```bash\n",
    "pip3 install --upgrade pip setuptools wheel\n",
    "```\n",
    "\n",
    "and then run:\n",
    "```bash\n",
    "pip3 install -r env_setup/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7c2e2",
   "metadata": {},
   "source": [
    "## Data Importing and Pre-processing <a class=\"anchor\" id=\"data-importing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6d947",
   "metadata": {},
   "source": [
    "Section Overview:\n",
    "\n",
    "- Import dataset and describe characteristics such as dimensions, data types, file types, and import methods used\n",
    "- Clean, wrangle, and handle missing data, duplicate data, etc.\n",
    "- Encode any categorical variables\n",
    "- Perform feature engineering on the dataset\n",
    "- Transform data appropriately using techniques such as aggregation, normalization, and feature construction\n",
    "- Reduce redundant data and perform need based discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33ac1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import warnings\n",
    "\n",
    "import branca\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from branca.element import Figure\n",
    "from folium import Marker\n",
    "from folium.plugins import HeatMap\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import norm, probplot, skew\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from utils.model_scripts import (\n",
    "    hello\n",
    ")\n",
    "from utils.metric_scripts import (\n",
    "    hello\n",
    ")\n",
    "from utils.data_validation import (\n",
    "    check_first_field\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas.*\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392754d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv(\"raw/player_valuations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea891c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/final_project_data_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/davidcariboo/player-scores?dataset_version_number=602&file_name=game_lineups.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233M/233M [00:05<00:00, 41.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    game_lineups_id        date  game_id  player_id  club_id  \\\n",
      "0  b2dbe01c3656b06c8e23e9de714e26bb  2013-07-27  2317258       1443      610   \n",
      "1  b50a3ec6d52fd1490aab42042ac4f738  2013-07-27  2317258       5017      610   \n",
      "2  7d890e6d0ff8af84b065839966a0ec81  2013-07-27  2317258       9602     1090   \n",
      "3  8c355268678b9bbc7084221b1f0fde36  2013-07-27  2317258      12282      610   \n",
      "4  76193074d549e5fdce4cdcbba0d66247  2013-07-27  2317258      25427     1090   \n",
      "\n",
      "         player_name             type            position number  team_captain  \n",
      "0  Christian Poulsen      substitutes  Defensive Midfield      5             0  \n",
      "1   Niklas Moisander  starting_lineup         Centre-Back      4             0  \n",
      "2    Maarten Martens      substitutes         Left Winger     11             0  \n",
      "3        Daley Blind  starting_lineup           Left-Back     17             0  \n",
      "4        Roy Beerens  starting_lineup        Right Winger     23             0  \n"
     ]
    }
   ],
   "source": [
    "# Importing dataset via Kaggle API \n",
    "\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"game_lineups.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"davidcariboo/player-scores\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf8fc1",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization <a class=\"anchor\" id=\"data-vis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932640b",
   "metadata": {},
   "source": [
    "Section Overview:\n",
    "\n",
    "- Identify categorical, ordinal, and numerical variables within data\n",
    "- Provide measures of centrality and distribution with visualizations\n",
    "- Diagnose for correlations between variables and determine independent and dependent variables\n",
    "- Perform exploratory analysis in combination with visualization techniques to discover patterns and features of interest\n",
    "- Create visualizations that allow for the discovery of insights in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889b2d8",
   "metadata": {},
   "source": [
    "## Data Analytics <a class=\"anchor\" id=\"data-analytics\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
